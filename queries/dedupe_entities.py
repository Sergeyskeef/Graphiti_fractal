#!/usr/bin/env python3
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ Entity —É–∑–ª–æ–≤.
- –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç Entity –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∏–º–µ–Ω–∏
- –û—Å—Ç–∞–≤–ª—è–µ—Ç –æ–¥–∏–Ω –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –≤–ª–∏–≤–∞–µ—Ç –≤ –Ω–µ–≥–æ
- –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –≤—Å–µ —Ä—ë–±—Ä–∞ –Ω–∞ –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª
"""

import asyncio
import logging
from collections import defaultdict
from datetime import datetime, timezone
from typing import Dict, List

from core.graphiti_client import get_graphiti_client
from core.text_utils import normalize_entity_name, is_meaningful_entity_name

logger = logging.getLogger(__name__)


async def fetch_entities(driver) -> List[Dict]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ Entity —É–∑–ª—ã —Å –∏—Ö –∏–º–µ–Ω–∞–º–∏ –∏ UUID.
    """
    res = await driver.execute_query(
        """
        MATCH (e:Entity)
        WHERE NOT e.deleted AND e.group_id IS NOT NULL
        RETURN e.uuid AS uuid, coalesce(e.name, '') AS name, e.group_id AS group_id
        """
    )
    entities = []
    for rec in res.records:
        name = rec["name"] or ""
        if not is_meaningful_entity_name(name):
            continue
        entities.append({
            "uuid": rec["uuid"],
            "name": name,
            "normalized_name": normalize_entity_name(name),
            "group_id": rec["group_id"]
        })
    return entities


async def fetch_entity_relationships(driver, entity_uuid: str) -> Dict[str, List[str]]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –≤—Ö–æ–¥—è—â–∏–µ –∏ –∏—Å—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏ —Å—É—â–Ω–æ—Å—Ç–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict —Å –∫–ª—é—á–∞–º–∏ 'incoming' –∏ 'outgoing'.
    """
    # –ò—Å—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
    outgoing_res = await driver.execute_query(
        """
        MATCH (e:Entity {uuid: $uuid})-[r]->(target)
        RETURN type(r) AS rel_type, target.uuid AS target_uuid
        """,
        uuid=entity_uuid
    )

    # –í—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
    incoming_res = await driver.execute_query(
        """
        MATCH (source)-[r]->(e:Entity {uuid: $uuid})
        RETURN type(r) AS rel_type, source.uuid AS source_uuid
        """,
        uuid=entity_uuid
    )

    return {
        "outgoing": [{"rel_type": rec["rel_type"], "target_uuid": rec["target_uuid"]}
                    for rec in outgoing_res.records],
        "incoming": [{"rel_type": rec["rel_type"], "source_uuid": rec["source_uuid"]}
                    for rec in incoming_res.records]
    }


async def merge_entity_properties(driver, from_uuids: List[str], to_uuid: str):
    """
    –°–ª–∏–≤–∞–µ—Ç —Å–≤–æ–π—Å—Ç–≤–∞ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö Entity —É–∑–ª–æ–≤ –≤ –æ–¥–∏–Ω –≥–ª–∞–≤–Ω—ã–π.
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è: merge & accumulate - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.
    """
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–≤–æ–π—Å—Ç–≤–∞ –∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    all_summaries = set()
    all_tags = set()

    for uuid in from_uuids + [to_uuid]:  # –í–∫–ª—é—á–∞—è –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª
        res = await driver.execute_query(
            """
            MATCH (e:Entity {uuid: $uuid})
            RETURN e.summary AS summary, e.tags AS tags
            """,
            uuid=uuid
        )
        if res.records:
            rec = res.records[0]
            if rec["summary"]:
                all_summaries.add(rec["summary"])
            if rec["tags"] and isinstance(rec["tags"], list):
                all_tags.update(rec["tags"])

    # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª
    if all_summaries:
        # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ summary - –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω —Ç–µ–∫—Å—Ç
        combined_summary = " | ".join(sorted(all_summaries))
        await driver.execute_query(
            """
            MATCH (e:Entity {uuid: $uuid})
            SET e.summary = $summary
            """,
            uuid=to_uuid,
            summary=combined_summary
        )

    if all_tags:
        await driver.execute_query(
            """
            MATCH (e:Entity {uuid: $uuid})
            SET e.tags = $tags
            """,
            uuid=to_uuid,
            tags=list(all_tags)
        )


async def merge_entity_relationships(driver, from_uuid: str, to_uuid: str):
    """
    –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –≤—Å–µ —Å–≤—è–∑–∏ —Å –æ–¥–Ω–æ–≥–æ Entity —É–∑–ª–∞ –Ω–∞ –¥—Ä—É–≥–æ–π.
    """
    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –∏—Å—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
    await driver.execute_query(
        """
        MATCH (from:Entity {uuid: $from_uuid})-[r]->(target)
        WHERE target.uuid <> $to_uuid  // –ù–µ —Å–æ–∑–¥–∞–µ–º –ø–µ—Ç–ª–∏
        MERGE (to:Entity {uuid: $to_uuid})-[r2:r.type]->(target)
        ON CREATE SET r2 = properties(r)
        DELETE r
        """,
        from_uuid=from_uuid,
        to_uuid=to_uuid
    )

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –≤—Ö–æ–¥—è—â–∏–µ —Å–≤—è–∑–∏
    await driver.execute_query(
        """
        MATCH (source)-[r]->(from:Entity {uuid: $from_uuid})
        WHERE source.uuid <> $to_uuid  // –ù–µ —Å–æ–∑–¥–∞–µ–º –ø–µ—Ç–ª–∏
        MERGE (source)-[r2:r.type]->(to:Entity {uuid: $to_uuid})
        ON CREATE SET r2 = properties(r)
        DELETE r
        """,
        from_uuid=from_uuid,
        to_uuid=to_uuid
    )


async def mark_entity_deleted(driver, uuid: str, merged_into: str):
    """
    –ü–æ–º–µ—á–∞–µ—Ç Entity –∫–∞–∫ —É–¥–∞–ª—ë–Ω–Ω—É—é –ø–æ—Å–ª–µ —Å–ª–∏—è–Ω–∏—è.
    """
    await driver.execute_query(
        """
        MATCH (e:Entity {uuid: $uuid})
        SET e.deleted = true,
            e.deleted_at = $deleted_at,
            e.merged_into = $merged_into
        """,
        uuid=uuid,
        deleted_at=datetime.now(timezone.utc).isoformat(),
        merged_into=merged_into
    )


async def deduplicate_entities(driver, entities: List[Dict]) -> Dict[str, int]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é Entity —É–∑–ª–æ–≤.
    –ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∏–º–µ–Ω–∏, –Ω–æ —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ group_id.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–ø–µ—Ä–∞—Ü–∏–π.
    """
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º—É –∏–º–µ–Ω–∏ –ò group_id
    groups = defaultdict(list)
    for entity in entities:
        key = f"{entity['normalized_name']}:{entity['group_id']}"
        groups[key].append(entity)

    stats = {
        "total_entities": len(entities),
        "unique_groups": len(groups),
        "duplicates_found": 0,
        "entities_merged": 0,
        "relationships_transferred": 0
    }

    for group_key, group_entities in groups.items():
        if len(group_entities) <= 1:
            continue  # –ù–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

        normalized_name, group_id = group_key.split(':', 1)
        stats["duplicates_found"] += len(group_entities) - 1

        # –í—ã–±–∏—Ä–∞–µ–º –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª (–ø–µ—Ä–≤—ã–π –ø–æ UUID)
        master_entity = min(group_entities, key=lambda x: x["uuid"])
        duplicate_entities = [e for e in group_entities if e["uuid"] != master_entity["uuid"]]

        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã '{normalized_name}' (group_id: {group_id}): –≥–ª–∞–≤–Ω—ã–π {master_entity['uuid']}, "
                   f"–¥—É–±–ª–∏–∫–∞—Ç–æ–≤ {len(duplicate_entities)}")

        # –°–ª–∏–≤–∞–µ–º —Å–≤–æ–π—Å—Ç–≤–∞ —Å–æ –≤—Å–µ—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ –≥–ª–∞–≤–Ω—ã–π
        all_uuids = [e["uuid"] for e in group_entities]
        await merge_entity_properties(driver, duplicate_entities, master_entity["uuid"])

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Å–≤—è–∑–∏ –∏ –ø–æ–º–µ—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∫–∞–∫ —É–¥–∞–ª–µ–Ω–Ω—ã–µ
        for duplicate in duplicate_entities:
            # –ü–æ–ª—É—á–∞–µ–º —Å–≤—è–∑–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞
            relationships = await fetch_entity_relationships(driver, duplicate["uuid"])

            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —Å–≤—è–∑–∏ –Ω–∞ –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª
            await merge_entity_relationships(driver, duplicate["uuid"], master_entity["uuid"])

            # –ü–æ–º–µ—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç –∫–∞–∫ —É–¥–∞–ª—ë–Ω–Ω—ã–π
            await mark_entity_deleted(driver, duplicate["uuid"], master_entity["uuid"])

            stats["entities_merged"] += 1
            stats["relationships_transferred"] += len(relationships["incoming"]) + len(relationships["outgoing"])

            logger.info(f"  –°–ª–∏—Ç {duplicate['uuid']} -> {master_entity['uuid']}: "
                       f"{len(relationships['incoming'])} –≤—Ö–æ–¥—è—â–∏—Ö, "
                       f"{len(relationships['outgoing'])} –∏—Å—Ö–æ–¥—è—â–∏—Ö —Å–≤—è–∑–µ–π")

    return stats


async def main(dry_run: bool = False):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏.
    """
    logging.basicConfig(level=logging.INFO,
                       format='%(asctime)s - %(levelname)s - %(message)s')

    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é Entity —É–∑–ª–æ–≤...")

    if dry_run:
        logger.info("üîç DRY RUN —Ä–µ–∂–∏–º - –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ –±—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã")

    graphiti = await get_graphiti_client().ensure_ready()
    driver = graphiti.driver

    # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ Entity —É–∑–ª—ã
    logger.info("üìä –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ Entity —É–∑–ª–æ–≤...")
    entities = await fetch_entities(driver)
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(entities)} Entity —É–∑–ª–æ–≤ —Å group_id")

    if not entities:
        logger.info("‚ùå Entity —É–∑–ª—ã —Å group_id –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    groups = defaultdict(list)
    for entity in entities:
        key = f"{entity['normalized_name']}:{entity['group_id']}"
        groups[key].append(entity)

    duplicates_total = sum(len(group) - 1 for group in groups.values() if len(group) > 1)

    logger.info("üìä –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
    logger.info(f"  –í—Å–µ–≥–æ Entity: {len(entities)}")
    logger.info(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø (–∏–º—è + group_id): {len(groups)}")
    logger.info(f"  –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicates_total}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    sorted_groups = sorted(groups.items(),
                          key=lambda x: len(x[1]),
                          reverse=True)
    logger.info("üîù –¢–æ–ø-10 –≥—Ä—É–ø–ø —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏:")
    for i, (group_key, group_entities) in enumerate(sorted_groups[:10], 1):
        if len(group_entities) > 1:
            normalized_name, group_id = group_key.split(':', 1)
            logger.info(f"  {i}. '{normalized_name}' (group: {group_id}): {len(group_entities)} —Å—É—â–Ω–æ—Å—Ç–µ–π")

    if dry_run:
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω (DRY RUN)")
        return

    # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é
    stats = await deduplicate_entities(driver, entities)

    logger.info("‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    logger.info("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    logger.info(f"  –í—Å–µ–≥–æ Entity: {stats['total_entities']}")
    logger.info(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä—É–ø–ø: {stats['unique_groups']}")
    logger.info(f"  –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['duplicates_found']}")
    logger.info(f"  –°–ª–∏—Ç–æ —Å—É—â–Ω–æ—Å—Ç–µ–π: {stats['entities_merged']}")
    logger.info(f"  –ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ —Å–≤—è–∑–µ–π: {stats['relationships_transferred']}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è Entity —É–∑–ª–æ–≤")
    parser.add_argument("--dry-run", action="store_true",
                       help="–ê–Ω–∞–ª–∏–∑ –±–µ–∑ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π")
    args = parser.parse_args()

    asyncio.run(main(dry_run=args.dry_run))